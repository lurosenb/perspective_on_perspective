{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e75734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from googleapiclient import discovery\n",
    "import json\n",
    "from googleapiclient.errors import HttpError\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401157ce",
   "metadata": {},
   "source": [
    "# Perspective vs. GPT-3 vs. Human Toxicity Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243f14c",
   "metadata": {},
   "source": [
    "## Load full benchmark CSV and API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd4ad61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the benchmark dataset\n",
    "data = pd.read_csv('../data/raw/full_toxicity_benchmark.tsv', sep='\\t')\n",
    "data = data.dropna(subset=['text']).reset_index(drop=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bfdd108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>Your secrets aren't so safe, if you know what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>Your parents wouldn't be too happy to know abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>You wouldn't want me to do something about tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>You know I've seen what you've done, don't you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>Listen to me, or I'll tell your husband what y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category       tag                                               text\n",
       "0  Blackmail  filtered  Your secrets aren't so safe, if you know what ...\n",
       "1  Blackmail  filtered  Your parents wouldn't be too happy to know abo...\n",
       "2  Blackmail  filtered  You wouldn't want me to do something about tha...\n",
       "3  Blackmail  filtered    You know I've seen what you've done, don't you?\n",
       "4  Blackmail  filtered  Listen to me, or I'll tell your husband what y..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73f588",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../perspective_api_key.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenapiedras/Documents/masters_classes/repos/spring2022/nlu/perspective_on_perspective/scripts/Perspective_GPT3_Human_Baseline.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenapiedras/Documents/masters_classes/repos/spring2022/nlu/perspective_on_perspective/scripts/Perspective_GPT3_Human_Baseline.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39m# Perspective API Key\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lorenapiedras/Documents/masters_classes/repos/spring2022/nlu/perspective_on_perspective/scripts/Perspective_GPT3_Human_Baseline.ipynb#ch0000005?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m../perspective_api_key.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenapiedras/Documents/masters_classes/repos/spring2022/nlu/perspective_on_perspective/scripts/Perspective_GPT3_Human_Baseline.ipynb#ch0000005?line=2'>3</a>\u001b[0m     PERSPECTIVE_API_KEY \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mrstrip()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../perspective_api_key.txt'"
     ]
    }
   ],
   "source": [
    "# Perspective API Key\n",
    "with open('../perspective_api_key.txt', 'r') as file:\n",
    "    PERSPECTIVE_API_KEY = file.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e78ca89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-3 API Key\n",
    "with open('../gpt3_key_2.txt', 'r') as file:\n",
    "    openai.api_key = file.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e402edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load human scoring sheets and join on text \n",
    "human_scores = pd.read_csv('../data/processed/norm_human_toxicity_scores.csv')\n",
    "human_scores = human_scores.dropna(subset=['text']).reset_index(drop=True)\n",
    "human_scores = human_scores.rename(columns={'toxicity': 'human_toxicity'})\n",
    "len(human_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb60e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a binarized label to comments using human scores (i.e. if human normalized score) > 0.5 -> toxic (1)\n",
    "human_threshold = 0.5\n",
    "\n",
    "human_scores[\"binary_label\"] = (human_scores[\"human_toxicity\"] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4861ca50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_toxicity</th>\n",
       "      <th>category</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.636</td>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>Your secrets aren't so safe, if you know what ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.651</td>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>Your parents wouldn't be too happy to know abo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.629</td>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>You wouldn't want me to do something about tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.658</td>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>You know I've seen what you've done, don't you?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.731</td>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>Listen to me, or I'll tell your husband what y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   human_toxicity   category       tag  \\\n",
       "0           0.636  Blackmail  filtered   \n",
       "1           0.651  Blackmail  filtered   \n",
       "2           0.629  Blackmail  filtered   \n",
       "3           0.658  Blackmail  filtered   \n",
       "4           0.731  Blackmail  filtered   \n",
       "\n",
       "                                                text  binary_label  \n",
       "0  Your secrets aren't so safe, if you know what ...             1  \n",
       "1  Your parents wouldn't be too happy to know abo...             1  \n",
       "2  You wouldn't want me to do something about tha...             1  \n",
       "3    You know I've seen what you've done, don't you?             1  \n",
       "4  Listen to me, or I'll tell your husband what y...             1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9b8db",
   "metadata": {},
   "source": [
    "## Set up Perspective and GPT-3 API Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19721f8e",
   "metadata": {},
   "source": [
    "### Perspective API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6885a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developers.perspectiveapi.com/s/about-the-api-attributes-and-languages\n",
    "possible_attributes = ['TOXICITY', 'THREAT', 'INSULT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3eff6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_type_map_full = {\n",
    "    \"toxicity_score\": \"TOXICITY\",\n",
    "    \"identity_score\": \"IDENTITY_ATTACK\",\n",
    "    \"insult_score\": \"INSULT\",\n",
    "    \"threat_score\": \"THREAT\",\n",
    "    \"sex_score\": \"SEXUALLY_EXPLICIT\",\n",
    "    \"flirtation_score\": \"FLIRTATION\"\n",
    "}\n",
    "\n",
    "score_type_map_toxicity = {\n",
    "    \"toxicity_score\": \"TOXICITY\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17b0e6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"attributeScores\": {\n",
      "    \"TOXICITY\": {\n",
      "      \"spanScores\": [\n",
      "        {\n",
      "          \"begin\": 0,\n",
      "          \"end\": 40,\n",
      "          \"score\": {\n",
      "            \"value\": 0.074325636,\n",
      "            \"type\": \"PROBABILITY\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"summaryScore\": {\n",
      "        \"value\": 0.074325636,\n",
      "        \"type\": \"PROBABILITY\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"languages\": [\n",
      "    \"en\"\n",
      "  ],\n",
      "  \"detectedLanguages\": [\n",
      "    \"en\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Perspective API\n",
    "# Example manual test\n",
    "client = discovery.build(\n",
    "  \"commentanalyzer\",\n",
    "  \"v1alpha1\",\n",
    "  developerKey=PERSPECTIVE_API_KEY,\n",
    "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "  static_discovery=False,\n",
    ")\n",
    "\n",
    "analyze_request = {\n",
    "  'comment': { 'text': \"Congratulations, you totally deserve it!\"},\n",
    "  'requestedAttributes': {'TOXICITY': {}}\n",
    "}\n",
    "\n",
    "response = client.comments().analyze(body=analyze_request).execute()\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57a89b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_row_perspective(row, score_type_list, threshold=None, add_delay=False):\n",
    "    if add_delay:\n",
    "        time.sleep(1)\n",
    "    try:\n",
    "        score_type_attribute = {value: {} for value in score_type_list}\n",
    "        analyze_request = {\n",
    "            'comment': { 'text': row['text'] },\n",
    "            'requestedAttributes': score_type_attribute\n",
    "        }\n",
    "        response = client.comments().analyze(body=analyze_request).execute()\n",
    "    except HttpError as err:\n",
    "        if err.resp.status == 429:\n",
    "            print('Quota limit exceeded')\n",
    "            time.sleep(10)\n",
    "            response = client.comments().analyze(body=analyze_request).execute()\n",
    "        else:\n",
    "            raise\n",
    "    value_list = []\n",
    "    for score_type in score_type_list:\n",
    "        value_list.append(\n",
    "            response['attributeScores'][score_type]['summaryScore']['value'])\n",
    "    return tuple(value_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b85e5",
   "metadata": {},
   "source": [
    "### GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72bb27af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_bank = {\n",
    "      \"Prompt 'toxic'\": \"toxic\",\n",
    "      \"Prompt 'harmful'\": \"harmful\",\n",
    "      \"Prompt 'mean'\": \"mean\",\n",
    "      \"Prompt 'manipulative'\": \"manipulative\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2da6397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_prompt = \"toxic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2052cc4b",
   "metadata": {},
   "source": [
    "#### Temperature\n",
    "So, temperature ranges from 0.0-1.0, where 0.0 has no randomness, and 1.0 allows GPT-3 to be very \"creative.\" Temperature=0.0 will give the same exact result each time. For most natural language generation tasks, people set temperature at ~0.7. We can set it at 0.3 (which is good at just giving binary answers), and maybe also try values of 0.5, and 0.7 for comparison (which will probably involve us parsing some responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21d5100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef836789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toxicity_sentiment_prompt_zero_shot(phrase, prompt_type):\n",
    "    return f\"\"\"Tr ue or False, the phrase '{phrase}' is {prompt_type}?\n",
    "    Answer:\"\"\"\n",
    "\n",
    "def parse_boolean_text(t):\n",
    "    # NOTE: We assume here that we get an answer from a well behaved set\n",
    "    # We signify another response (should be rare) with -1,\n",
    "    # and inspect these by hand\n",
    "    t = t.lower().split(' ')\n",
    "    for val in ['true', 'false', 'yes', 'no', 'true.', 'false.', 'yes.', 'no.']:\n",
    "        if val in t:\n",
    "            return int(val == 'true') or int(val == 'yes')\n",
    "\n",
    "    # Special case: sometimes GPT3 returns a negation.\n",
    "    # I.e. \"This phrase is not toxic\" -> false\n",
    "    # this might be a bit of a hacky fix...\n",
    "    if 'not' in t:\n",
    "        return 0\n",
    "    return -1\n",
    "\n",
    "def score_row_gpt3(row, prompt_type, shot_num='zero', add_delay=True):\n",
    "    if shot_num == 'zero':\n",
    "        prompt = toxicity_sentiment_prompt_zero_shot(row['text'], prompt_type)\n",
    "    elif shot_num == 'one':\n",
    "        prompt = f\"\"\"Determine if the given phrase is toxic:\n",
    "                   Men are superior to women in every way. => True\n",
    "                   {row['text']} =>\"\"\"\n",
    "    elif shot_num == 'few':\n",
    "        prompt = f\"\"\"Determine if the given phrase is toxic:\n",
    "                   Men are superior to women in every way. => True\n",
    "                   Grilling with the neighbors is my favorite. => False\n",
    "                   {row['text']} =>\"\"\"\n",
    "    \n",
    "    if add_delay:\n",
    "        time.sleep(1)\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "                engine=\"text-davinci-001\",\n",
    "                prompt=prompt,\n",
    "                temperature=temperature,\n",
    "              )\n",
    "    except:\n",
    "        time.sleep(10)\n",
    "        response = openai.Completion.create(\n",
    "                engine=\"text-davinci-001\",\n",
    "                prompt=prompt,\n",
    "                temperature=temperature,\n",
    "              )\n",
    "    return parse_boolean_text(response[\"choices\"][0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22c7acfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" False\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1652052645,\n",
      "  \"id\": \"cmpl-55keLxjTrGXGdXqXwSgIyO9ktyFAy\",\n",
      "  \"model\": \"text-davinci:001\",\n",
      "  \"object\": \"text_completion\"\n",
      "}\n",
      "Determine if the given phrase is toxic:\n",
      "                   Men are superior to women in every way. => True\n",
      "                   Grilling with the neighbors is my favorite. => False\n",
      "                   Boys are smarter than girls. =>\n",
      " False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Manual test\n",
    "phrase_input_fewshot = \"Boys are smarter than girls.\"\n",
    "few_shot_prompt = f\"\"\"Determine if the given phrase is toxic:\n",
    "                   Men are superior to women in every way. => True\n",
    "                   Grilling with the neighbors is my favorite. => False\n",
    "                   {phrase_input_fewshot} =>\"\"\"\n",
    "response = openai.Completion.create(\n",
    "              engine=\"text-davinci-001\",\n",
    "              prompt=few_shot_prompt,\n",
    "              temperature=temperature,\n",
    "            )\n",
    "print(response)\n",
    "print(few_shot_prompt)\n",
    "# print(\"For prompt: \" + toxic_prompt)\n",
    "print(response[\"choices\"][0][\"text\"])\n",
    "print(parse_boolean_text(response[\"choices\"][0][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9489856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" False\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1652052698,\n",
      "  \"id\": \"cmpl-55kfCYG6ll6JkfedCIhIZafuyOC0Z\",\n",
      "  \"model\": \"text-davinci:001\",\n",
      "  \"object\": \"text_completion\"\n",
      "}\n",
      "True or False, the phrase 'Boys should just play sports, girls should just play dress-up' is toxic?\n",
      "    Answer:\n",
      "For prompt: toxic\n",
      " False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Manual test - zero shot\n",
    "phrase = 'Boys should just play sports, girls should just play dress-up'\n",
    "\n",
    "response = openai.Completion.create(\n",
    "              engine=\"text-davinci-001\",\n",
    "              prompt=toxicity_sentiment_prompt_zero_shot(phrase, toxic_prompt),\n",
    "              temperature=temperature,\n",
    "            )\n",
    "print(response)\n",
    "print(toxicity_sentiment_prompt_zero_shot(phrase, toxic_prompt))\n",
    "print(\"For prompt: \" + toxic_prompt)\n",
    "print(response[\"choices\"][0][\"text\"])\n",
    "print(parse_boolean_text(response[\"choices\"][0][\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f3778f",
   "metadata": {},
   "source": [
    "# Test GPT-3 (multiple settings) and PerspectiveAPI across the benchmark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d3687b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d7170a",
   "metadata": {},
   "source": [
    "### GPT-3 Runs\n",
    "This will take a few minutes.\n",
    "\n",
    "Experimental design:\n",
    "- 3 runs of GPT zero, one, and few-shot\n",
    "- Take the \"majority vote\" of the runs for each comment\n",
    "- Use the majority in the final scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cdbb8a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN:  1\n",
      "GPT Zero Running.\n",
      "GPT Zero Complete.\n",
      "GPT One-Shot Running.\n",
      "GPT One-Shot Complete.\n",
      "GPT-3 Few Shot Running.\n",
      "GPT-3 Few Shot Complete\n",
      "RUN:  2\n",
      "GPT Zero Running.\n",
      "GPT Zero Complete.\n",
      "GPT One-Shot Running.\n",
      "GPT One-Shot Complete.\n",
      "GPT-3 Few Shot Running.\n",
      "GPT-3 Few Shot Complete\n",
      "RUN:  3\n",
      "GPT Zero Running.\n",
      "GPT Zero Complete.\n",
      "GPT One-Shot Running.\n",
      "GPT One-Shot Complete.\n",
      "GPT-3 Few Shot Running.\n",
      "GPT-3 Few Shot Complete\n"
     ]
    }
   ],
   "source": [
    "prompt_type = \"toxic\"\n",
    "\n",
    "for r in ['r1', 'r2', 'r3']:\n",
    "    print(\"RUN: \",  r[1])\n",
    "    # GPT-3 zero-shot for binary toxicity classification\n",
    "    print(\"GPT Zero Running.\")\n",
    "    exp_results[f'GPT3_zero_shot_toxicity_{r}'] = exp_results.apply(lambda row: score_row_gpt3(row, \n",
    "                                                                            prompt_type=prompt_type, \n",
    "                                                                            shot_num='zero',\n",
    "                                                                            add_delay=True), axis=1)    \n",
    "\n",
    "    print(\"GPT Zero Complete.\")\n",
    "    # GPT-3 one-shot for binary toxicity classification\n",
    "    print(\"GPT One-Shot Running.\")\n",
    "    exp_results[f'GPT3_one_shot_toxicity_{r}'] = exp_results.apply(lambda row: score_row_gpt3(row, \n",
    "                                                                           prompt_type=prompt_type, \n",
    "                                                                           shot_num='one',\n",
    "                                                                           add_delay=True),\n",
    "                                                axis=1)\n",
    "    print(\"GPT One-Shot Complete.\")\n",
    "\n",
    "    # GPT-3 few-shot for binary toxicity classification\n",
    "    print(\"GPT-3 Few Shot Running.\")\n",
    "    exp_results[f'GPT3_few_shot_toxicity_{r}'] = exp_results.apply(lambda row: score_row_gpt3(row, \n",
    "                                                                           prompt_type=prompt_type, \n",
    "                                                                           shot_num='few',\n",
    "                                                                           add_delay=True),\n",
    "                                           axis=1)   \n",
    "    print(\"GPT-3 Few Shot Complete\")\n",
    "    \n",
    "    exp_results.to_csv('../data/interim/gpt_exp_results_progress.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c7129",
   "metadata": {},
   "source": [
    "### Perspective Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a05faaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN:  1\n",
      "RUN:  2\n",
      "RUN:  3\n"
     ]
    }
   ],
   "source": [
    "perspective_threshold = 0.5 # Threshold for binarizing Perspective toxicity predictions\n",
    "\n",
    "# This is hard-coded just to use toxicity here, but can be changed if we want to look at other scores\n",
    "# score_col_names = list(score_type_map_toxicity.keys()) #list(score_type_map_full.keys())\n",
    "score_type_list = list(score_type_map_toxicity.values()) #list(score_type_map_full.values())\n",
    "\n",
    "\n",
    "for r in ['r1', 'r2', 'r3']:\n",
    "    print(\"RUN: \",  r[1])\n",
    "    # Perspective API toxicity scoring\n",
    "    exp_results[f'perspective_toxicity_score_{r}'] = data.apply(lambda row: score_row_perspective(\n",
    "        row, \n",
    "        score_type_list=score_type_list, \n",
    "        add_delay=True), axis=1, result_type='expand')\n",
    "    exp_results.to_csv('../data/interim/perspective_exp_results_progress.csv', index=False)\n",
    "#     results.columns = score_col_names\n",
    "#     data = data.join(results)\n",
    "#     data = data.rename(columns={'toxicity_score': \"perspective_toxicity_score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bc3e9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results.to_csv('../data/interim/all_tests_run.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ecb81aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results = pd.read_csv('../data/interim/all_tests_run.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6af4c",
   "metadata": {},
   "source": [
    "### Post-processing (i.e. thresholding scores and formatting table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "daddfc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with the human baseline\n",
    "merged_data = pd.merge(left=exp_results, \n",
    "                   right=human_scores[['text', 'human_toxicity', 'binary_label']],\n",
    "                   left_on='text',\n",
    "                    right_on='text',\n",
    "                    how='left',\n",
    "                   sort=True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bfd1e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = merged_data.sort_values('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607dc40c",
   "metadata": {},
   "source": [
    "#### Take majority vote of GPT3 results (i.e. mode) and average of perspective scores to simplify dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "578fae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(curr_list):\n",
    "    occurence_count = Counter(curr_list)\n",
    "    return occurence_count.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b26bf56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority for GPT3 Results\n",
    "zero_shot = sorted_results[['GPT3_zero_shot_toxicity_r1', 'GPT3_zero_shot_toxicity_r2', 'GPT3_zero_shot_toxicity_r3']].values.tolist()\n",
    "zero_shot_majority = []\n",
    "for z in zero_shot:\n",
    "    zero_shot_majority.append(most_frequent(z))\n",
    "    \n",
    "one_shot = sorted_results[['GPT3_one_shot_toxicity_r1', 'GPT3_one_shot_toxicity_r2', 'GPT3_one_shot_toxicity_r3']].values.tolist()\n",
    "one_shot_majority = []\n",
    "for o in one_shot:\n",
    "    one_shot_majority.append(most_frequent(o))\n",
    "    \n",
    "few_shot = sorted_results[['GPT3_few_shot_toxicity_r1', 'GPT3_few_shot_toxicity_r2', 'GPT3_few_shot_toxicity_r3']].values.tolist()\n",
    "few_shot_majority = []\n",
    "for f in few_shot:\n",
    "    few_shot_majority.append(most_frequent(f))     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "27ebffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average for perspective results\n",
    "perspective_avgs = list(sorted_results[['perspective_toxicity_score_r1', 'perspective_toxicity_score_r2',\n",
    "                       'perspective_toxicity_score_r3']].mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0da246fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_trimmed = sorted_results[['category', 'tag', 'text', 'human_toxicity', 'binary_label']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1f170d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_trimmed['perspective_avg_toxicity'] = perspective_avgs\n",
    "sorted_trimmed['gpt_zero_shot_mode'] = zero_shot_majority\n",
    "sorted_trimmed['gpt_one_shot_mode'] = one_shot_majority\n",
    "sorted_trimmed['gpt_few_shot_mode'] = few_shot_majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "51fc5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the perspective API scores\n",
    "sorted_trimmed[f'perspective_toxic_thresholded_{perspective_threshold}'] = (sorted_trimmed['perspective_avg_toxicity'] > perspective_threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "89d78a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_trimmed.to_csv('../data/processed/final_experiment_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f9837",
   "metadata": {},
   "source": [
    "## Get accuracy for different models against human label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "22372eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e959118c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'tag', 'text', 'human_toxicity', 'binary_label',\n",
       "       'perspective_avg_toxicity', 'gpt_zero_shot_mode', 'gpt_one_shot_mode',\n",
       "       'gpt_few_shot_mode', 'perspective_toxic_thresholded_0.5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_trimmed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a43d6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_zero_results = list(sorted_trimmed['gpt_zero_shot_mode'])\n",
    "gpt_one_results = list(sorted_trimmed['gpt_one_shot_mode'])\n",
    "gpt_few_results = list(sorted_trimmed['gpt_few_shot_mode'])\n",
    "perspective_results = list(sorted_trimmed['perspective_toxic_thresholded_0.5'])\n",
    "\n",
    "true_labels = list(sorted_trimmed['binary_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2f224b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['f1', 'precision', 'recall']\n",
    "\n",
    "col_map = {\n",
    "    'gpt_0': gpt_zero_results,\n",
    "    'gpt_1': gpt_one_results,\n",
    "    'gpt_few': gpt_few_results,\n",
    "    'perspective': perspective_results \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "19d88bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for score_name in scores:\n",
    "    for col_name, col_res in col_map.items():\n",
    "        if score_name == 'f1':\n",
    "            curr_score = f1_score(true_labels, col_res)\n",
    "        elif score_name == 'precision':\n",
    "            curr_score = precision_score(true_labels, col_res)\n",
    "        elif score_name == 'recall':\n",
    "            curr_score = recall_score(true_labels, col_res)\n",
    "\n",
    "        all_scores.append({'score_type': score_name,\n",
    "                            'method': col_name,\n",
    "                            'score_result': curr_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "caf6a0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_type</th>\n",
       "      <th>method</th>\n",
       "      <th>score_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1</td>\n",
       "      <td>gpt_0</td>\n",
       "      <td>0.313901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1</td>\n",
       "      <td>gpt_1</td>\n",
       "      <td>0.193237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1</td>\n",
       "      <td>gpt_few</td>\n",
       "      <td>0.606452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.083721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>precision</td>\n",
       "      <td>gpt_0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>precision</td>\n",
       "      <td>gpt_1</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>precision</td>\n",
       "      <td>gpt_few</td>\n",
       "      <td>0.728682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>precision</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recall</td>\n",
       "      <td>gpt_0</td>\n",
       "      <td>0.193370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>recall</td>\n",
       "      <td>gpt_1</td>\n",
       "      <td>0.110497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>recall</td>\n",
       "      <td>gpt_few</td>\n",
       "      <td>0.519337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>recall</td>\n",
       "      <td>perspective</td>\n",
       "      <td>0.049724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score_type       method  score_result\n",
       "0          f1        gpt_0      0.313901\n",
       "1          f1        gpt_1      0.193237\n",
       "2          f1      gpt_few      0.606452\n",
       "3          f1  perspective      0.083721\n",
       "4   precision        gpt_0      0.833333\n",
       "5   precision        gpt_1      0.769231\n",
       "6   precision      gpt_few      0.728682\n",
       "7   precision  perspective      0.264706\n",
       "8      recall        gpt_0      0.193370\n",
       "9      recall        gpt_1      0.110497\n",
       "10     recall      gpt_few      0.519337\n",
       "11     recall  perspective      0.049724"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame(all_scores)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c96fe162",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df.to_csv('../data/processed/acc_scores_for_paper.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d126a977",
   "metadata": {},
   "source": [
    "### Mean toxicity scores across our different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "738ea150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "      <th>human_toxicity</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>perspective_avg_toxicity</th>\n",
       "      <th>gpt_zero_shot_mode</th>\n",
       "      <th>gpt_one_shot_mode</th>\n",
       "      <th>gpt_few_shot_mode</th>\n",
       "      <th>perspective_toxic_thresholded_0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>I know what you did and I'm going to tell ever...</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>Listen to me, or I'll tell your husband what y...</td>\n",
       "      <td>0.731</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>I’ll always love you, but if you don’t give me...</td>\n",
       "      <td>0.766</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Blackmail</td>\n",
       "      <td>unfiltered</td>\n",
       "      <td>Give me the money or I'll tell your kids who t...</td>\n",
       "      <td>0.795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159421</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Blackmail</td>\n",
       "      <td>filtered</td>\n",
       "      <td>Invite me to the party, or I'll tell him what ...</td>\n",
       "      <td>0.702</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084982</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category         tag                                               text  \\\n",
       "75   Blackmail    filtered  I know what you did and I'm going to tell ever...   \n",
       "122  Blackmail    filtered  Listen to me, or I'll tell your husband what y...   \n",
       "115  Blackmail    filtered  I’ll always love you, but if you don’t give me...   \n",
       "28   Blackmail  unfiltered  Give me the money or I'll tell your kids who t...   \n",
       "106  Blackmail    filtered  Invite me to the party, or I'll tell him what ...   \n",
       "\n",
       "     human_toxicity  binary_label  perspective_avg_toxicity  \\\n",
       "75            0.636             1                  0.083299   \n",
       "122           0.731             1                  0.152959   \n",
       "115           0.766             1                  0.349136   \n",
       "28            0.795             1                  0.159421   \n",
       "106           0.702             1                  0.084982   \n",
       "\n",
       "     gpt_zero_shot_mode  gpt_one_shot_mode  gpt_few_shot_mode  \\\n",
       "75                    1                  1                  1   \n",
       "122                   0                  0                  1   \n",
       "115                   1                  0                  0   \n",
       "28                    1                  0                  1   \n",
       "106                   1                  0                  1   \n",
       "\n",
       "     perspective_toxic_thresholded_0.5  \n",
       "75                                   0  \n",
       "122                                  0  \n",
       "115                                  0  \n",
       "28                                   0  \n",
       "106                                  0  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_trimmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0707fb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_toxicity</th>\n",
       "      <th>perspective_avg_toxicity</th>\n",
       "      <th>gpt_zero_shot_mode</th>\n",
       "      <th>gpt_one_shot_mode</th>\n",
       "      <th>gpt_few_shot_mode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blackmail</th>\n",
       "      <td>0.68236</td>\n",
       "      <td>0.157348</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classism</th>\n",
       "      <td>0.78988</td>\n",
       "      <td>0.203953</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exclusionary</th>\n",
       "      <td>0.83560</td>\n",
       "      <td>0.233945</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive</th>\n",
       "      <td>0.05192</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaslighting</th>\n",
       "      <td>0.56496</td>\n",
       "      <td>0.155328</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Misogyny</th>\n",
       "      <td>0.78468</td>\n",
       "      <td>0.217520</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.103590</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sarcasm</th>\n",
       "      <td>0.66456</td>\n",
       "      <td>0.337378</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sexual Harassment</th>\n",
       "      <td>0.80028</td>\n",
       "      <td>0.219396</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stereotyping</th>\n",
       "      <td>0.81352</td>\n",
       "      <td>0.316959</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    human_toxicity  perspective_avg_toxicity  \\\n",
       "category                                                       \n",
       "Blackmail                  0.68236                  0.157348   \n",
       "Classism                   0.78988                  0.203953   \n",
       "Exclusionary               0.83560                  0.233945   \n",
       "False Positive             0.05192                  0.797110   \n",
       "Gaslighting                0.56496                  0.155328   \n",
       "Misogyny                   0.78468                  0.217520   \n",
       "Neutral                    0.00696                  0.103590   \n",
       "Sarcasm                    0.66456                  0.337378   \n",
       "Sexual Harassment          0.80028                  0.219396   \n",
       "Stereotyping               0.81352                  0.316959   \n",
       "\n",
       "                    gpt_zero_shot_mode  gpt_one_shot_mode  gpt_few_shot_mode  \n",
       "category                                                                      \n",
       "Blackmail                         0.48               0.40               0.76  \n",
       "Classism                          0.12               0.04               0.56  \n",
       "Exclusionary                      0.08               0.28               0.72  \n",
       "False Positive                    0.24               0.24               0.84  \n",
       "Gaslighting                       0.24               0.00               0.44  \n",
       "Misogyny                          0.20               0.08               0.60  \n",
       "Neutral                           0.00               0.00               0.28  \n",
       "Sarcasm                           0.12               0.00               0.24  \n",
       "Sexual Harassment                 0.12               0.00               0.36  \n",
       "Stereotyping                      0.08               0.00               0.36  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_stats = sorted_trimmed.groupby(['category'])[['human_toxicity', \n",
    "                                                  'perspective_avg_toxicity',\n",
    "                                                  'gpt_zero_shot_mode', \n",
    "                                                  'gpt_one_shot_mode',\n",
    "                                                  'gpt_few_shot_mode',\n",
    "\n",
    "                            ]].apply(np.mean)\n",
    "cat_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "60683e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_csv('../data/processed/exp_category_stats_for_paper.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e088e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67aa8fea817e95b662a6671f6771d805ffcf08a0d1b7852360fd97450de6b82a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('perspective')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
